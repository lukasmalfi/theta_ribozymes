{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import random\n",
    "import feather\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import subprocess\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import fontTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the color function later used by the wordcloud\n",
    "def red_color_func(word, font_size, position, orientation, random_state=None,\n",
    "                    **kwargs):\n",
    "    i=255-int(font_size*1.5)\n",
    "    o=225-int(font_size*1.5)\n",
    "    #return \"RGB(\"+str(o)+\",\"+str(i)+\",255)\" \n",
    "    return \"RGB(255,\"+str(i)+\",0)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file \"WGS_ribo_trna.csv\" into a DataFrame and store it in the \"wgs_theta\" variable\n",
    "wgs_theta=pd.read_csv(\"../tables_and_results/WGS_ribo_trna.csv\",sep=\"\\t\")\n",
    "\n",
    "#load file from microbe atlas to get the sample names and keywords\n",
    "keyw=pd.read_csv(\"/mnt/mnemo4/microbeatlas/mapdata/20210104map1/samples.env.simple\",\"\\t\",header=None)\n",
    "\n",
    "# Loop through a list of keywords and print the number of samples in the \"keyw\" DataFrame that have each keyword\n",
    "#Background distribution of the environments in all samples\n",
    "for x in [\"animal\",\"soil\",\"aquatic\",\"plant\"]:\n",
    "    print(x +\" found in \"+str(len(keyw[keyw[1]==x]))+\" samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the sequencing run ID for each found theta ribozyme\n",
    "samples=[]\n",
    "\n",
    "# Loop through the \"ID\" column of the \"wgs_theta\" DataFrame\n",
    "for x in wgs_theta[\"ID\"]:\n",
    "    # Split the current ID string at the \".\" character and append the first part to the \"samples\" list\n",
    "    samples.append(x.split(\".\")[0])\n",
    "\n",
    "# Create a deep copy of the \"keyw\" DataFrame and store it in the \"keyw_2\" variable\n",
    "keyw_2=keyw.copy(deep=True)\n",
    "\n",
    "# Split the values in the \"0\" column of the \"keyw_2\" DataFrame at the \".\" character and store the first part in a new list\n",
    "allspls=keyw_2.loc[:,0].str.split(\".\")\n",
    "ind=[]\n",
    "for x in allspls:\n",
    "    ind.append(x[0])\n",
    "\n",
    "# Set the index of the \"keyw_2\" DataFrame to the values in the \"ind\" list\n",
    "keyw_2.index=ind\n",
    "\n",
    "# Create an empty list to store the environment for each sequencing run ID in the \"samples\" list\n",
    "envs=[]\n",
    "\n",
    "# Loop through the sequencing run IDs in the \"samples\" list\n",
    "for sa in samples:\n",
    "    try:\n",
    "        # Get the environment for the current sequencing run ID from the \"keyw_2\" DataFrame and append it to the \"envs\" list\n",
    "        envs.append(keyw_2.loc[sa,1])\n",
    "    except:\n",
    "        # If the current sequencing run ID is not found in the \"keyw_2\" DataFrame, print an error message\n",
    "        print(sa+\" not found\")\n",
    "\n",
    "# Remove any NaN values from the \"envs\" list\n",
    "envs2 = [x for x in envs if str(x) != 'nan']\n",
    "\n",
    "# Initialize counters for each environment type\n",
    "animal=0\n",
    "soil=0\n",
    "aquatic=0\n",
    "plant=0\n",
    "ww=0\n",
    "\n",
    "# Loop through the environments in the \"envs2\" list and increment the corresponding counter for each environment type\n",
    "for env in envs2:\n",
    "    if \"animal\" in env:\n",
    "        animal+=1\n",
    "    if \"soil\" in env:\n",
    "        soil+=1\n",
    "    # Exclude wastewater due to \"human\" contamination\n",
    "    if \"aquatic\" in env:\n",
    "        if \"waste water\" not in env:\n",
    "            aquatic+=1\n",
    "        else:\n",
    "            ww+=1\n",
    "    if \"plant\" in env:\n",
    "        plant+=1\n",
    "\n",
    "# Print the number of theta ribozymes found in each environment type\n",
    "print(\"animal: \"+str(animal)+\" \\nsoil: \"+str(soil)+\" \\naquatic: \"+str(aquatic)+\" \\nplant: \"+str(plant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the \"STOPWORDS\" set from the \"wordcloud\" library\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "# Add custom stopwords to the \"STOPWORDS\" set\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update([\"nan\",\"raw\",\"association\",\"associ\",\"pl\"])\n",
    "stopwords.update([\"wat\",\"sourcetracker\",\"altamaha\",\"itasca\",\"keywords\",\"wate\",\"ti\",\"gsc\"])\n",
    "\n",
    "# Create an empty list to store the keywords for each sequencing run ID in the \"samples\" list\n",
    "words=[]\n",
    "\n",
    "# Loop through the sequencing run IDs in the \"samples\" list\n",
    "for sa in samples:\n",
    "    try:\n",
    "        # Get the keywords for the current sequencing run ID from the \"keyw_2\" DataFrame and append them to the \"words\" list\n",
    "        words.append(keyw_2.loc[sa,4])\n",
    "    except:\n",
    "        # If the current sequencing run ID is not found in the \"keyw_2\" DataFrame, print an error message\n",
    "        print(sa+\" not found\")\n",
    "\n",
    "# Create an empty list to store all individual keywords from the \"words\" list\n",
    "allwords_theta=[]\n",
    "\n",
    "# Loop through the strings in the \"words\" list\n",
    "for lin in words:\n",
    "    try:\n",
    "        # Split the current string at the \",\" character and loop through the resulting list of keywords\n",
    "        for word in lin.split(\",\"):\n",
    "            # Append the current keyword to the \"allwords_theta\" list\n",
    "            allwords_theta.append(word)\n",
    "    except:\n",
    "        # If an error occurs during the splitting process, print the current string\n",
    "        print(lin)\n",
    "#count the words of theta rz\n",
    "\n",
    "\n",
    "#count and sort the top 15 words found\n",
    "count=Counter(allwords_theta)\n",
    "print(count.most_common(15))\n",
    "\n",
    "#create and save the wordcloud\n",
    "\n",
    "wc=WordCloud(color_func=red_color_func, stopwords=stopwords,prefer_horizontal=1, min_font_size=10, max_font_size=150, relative_scaling=.4, width=1000, collocations=False,height=400, max_words=15, random_state=1, background_color=\"white\").generate(str(words).replace(\"'\",\"\"))\n",
    "\n",
    "wordcloud_svg = wc.to_svg(embed_font=True)\n",
    "f = open(\"wordcloud_theta_red.svg\",\"w+\")\n",
    "f.write(wordcloud_svg )\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random 10000 samples as a comparison to the wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all rows in the \"keyw_2\" DataFrame where the value in the \"4\" column is not NaN and store the result in the \"nonakeyw\" variable\n",
    "nonakeyw=keyw_2[~keyw_2[4].isna()]\n",
    "\n",
    "# Set the random seed to 106 (analysis performed on 10.6) and select 10,000 random rows from the \"nonakeyw\" DataFrame\n",
    "rnd=nonakeyw.sample(10000,random_state=106)\n",
    "\n",
    "# Create an empty list to store all individual keywords from the selected rows\n",
    "allwords=[]\n",
    "for lin in rnd[4]:\n",
    "    # Split the current string at the \",\" character and loop through the resulting list of keywords\n",
    "    for word in lin.split(\",\"):\n",
    "        # Append the current keyword to the \"allwords\" list\n",
    "        allwords.append(word)\n",
    "\n",
    "# Count the frequency of each keyword in the \"allwords\" list and print the 15 most common keywords\n",
    "count=Counter(allwords)\n",
    "count.most_common(15)\n",
    "\n",
    "# Create a WordCloud object with custom settings and generate a word cloud from the \"4\" column of the \"rnd\" DataFrame\n",
    "wc2=WordCloud(color_func=red_color_func, stopwords=stopwords,prefer_horizontal=1, min_font_size=10, max_font_size=150, relative_scaling=.4, width=1000, collocations=False,height=400, max_words=15, random_state=1, background_color=\"white\").generate(\",\".join(rnd[4].values))\n",
    "\n",
    "# Convert the generated word cloud to an SVG image and write it to a file named \"wordcloud_random.svg\"\n",
    "wordcloud_svg2 = wc2.to_svg(embed_font=True)\n",
    "f = open(\"wordcloud_random.svg\",\"w+\")\n",
    "f.write(wordcloud_svg2 )\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
